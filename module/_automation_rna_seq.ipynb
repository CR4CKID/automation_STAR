{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 13:36:11\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "#=============================================================================#\n",
    "# Author    : DaeHee Kim\n",
    "# Date      : 2025-05-30\n",
    "# Usage     : RNA-seq 자동화 개선버전\n",
    "# Example   : \n",
    "# Description   : \n",
    "#=============================================================================#\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "1. GSM을 SRR로 변환\n",
    "2. SRR을 prefetch\n",
    "3. SRA 파일 fasterq-dump\n",
    "4. STAR로 align, fastq 파일 삭제, bam 파일 삭제\n",
    "5. ReadsPerGene 파일 각 GSM 별로 이동\n",
    "6. Deseq2 분석\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import glob, random, os, time, argparse, requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "file = \"test_dataset.xlsx\"\n",
    "core = 32\n",
    "genome = \"hs\"\n",
    "\n",
    "if genome == \"mm\":\n",
    "    star_index = \"/program/STAR_index/mm10\"\n",
    "elif genome == \"hs\":\n",
    "    star_index = \"/program/STAR_index/hg38\"\n",
    "elif genome == \"sc\":\n",
    "    star_index = \"/program/STAR_index/r64\"\n",
    "elif genome == \"dm\":\n",
    "    star_index = \"/program/STAR_index/BDGP6\"\n",
    "elif genome == \"mg\":\n",
    "    star_index = \"/program/STAR_index/mg10\"\n",
    "elif genome == \"xl\":\n",
    "    star_index = \"/program/STAR_index/xl10\"\n",
    "    \n",
    "if not os.path.isdir(\"1_prefetch\"):\n",
    "    os.mkdir(\"1_prefetch\")\n",
    "if not os.path.isdir(\"2_fastq\"):\n",
    "    os.mkdir(\"2_fastq\")\n",
    "if not os.path.isdir(\"3_fastq_combined\"):\n",
    "    os.mkdir(\"3_fastq_combined\")\n",
    "if not os.path.isdir(\"4_aligned\"):\n",
    "    os.mkdir(\"4_aligned\")\n",
    "if not os.path.isdir(\"5_ReadsPerGenes_GSM\"):\n",
    "    os.mkdir(\"5_ReadsPerGenes_GSM\")\n",
    "if not os.path.isdir(\"6_deseq2_results\"):\n",
    "    os.mkdir(\"6_deseq2_results\")\n",
    "if not os.path.isdir(f\"./6_deseq2_results/merged\"):\n",
    "    os.mkdir(f\"./6_deseq2_results/merged\")\n",
    "if not os.path.isdir(f\"./6_deseq2_results/norm\"):\n",
    "    os.mkdir(f\"./6_deseq2_results/norm\")\n",
    "if not os.path.isdir(f\"./6_deseq2_results/deseq2\"):\n",
    "    os.mkdir(f\"./6_deseq2_results/deseq2\")\n",
    "\n",
    "\n",
    "with open(\"log\", \"w\") as f:\n",
    "    pass \n",
    "    \n",
    "#=============================================================================#\n",
    "\n",
    "# 출력 및 로그 작성용 함수\n",
    "def log_writer(text, line=False):\n",
    "    with open(\"log\", \"a\") as f:\n",
    "        if line:\n",
    "            f.write(\"#\"*80)\n",
    "            f.write(\"\\n\")\n",
    "        else:\n",
    "            f.write(\"\\n\")\n",
    "        #print(text)\n",
    "        f.write(text)\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "#=============================================================================#\n",
    "\n",
    "# 시작 파일은 GSE \\t GSM,GSM \\t GSM,GSM 으로 구성\n",
    "start_time = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(start_time)\n",
    "\n",
    "df = pd.read_excel(file,header=0, names = ['GSE', 'Treat','Control'])\n",
    "\n",
    "grouped_data = defaultdict(list)\n",
    "for name, group in df.groupby('GSE'):\n",
    "    grouped_data[name] = group.to_dict(orient='records')\n",
    "\n",
    "#=============================================================================#\n",
    "\n",
    "# GSM을 SRR로 변환하는 함수\n",
    "def gsm_to_srr(gsm):\n",
    "    srr_arr = []\n",
    "    treat_url = \"https://trace.ncbi.nlm.nih.gov/Traces/sra/?sp=runinfo&acc=\" + gsm\n",
    "    try:\n",
    "        response = requests.get(treat_url)\n",
    "    except:\n",
    "        log_writer(f\"Gathering {gsm} info failed\", True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        lines = response.text.strip().split(\"\\n\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve data: Status code\", response.status_code)\n",
    "        \n",
    "    for line in lines[1:]:\n",
    "        line = line.strip().split(\",\")\n",
    "        srr_num = line[0]\n",
    "        srr_arr.append(srr_num)\n",
    "    return srr_arr\n",
    "\n",
    "#=============================================================================#\n",
    "\n",
    "# 겹치는 GSE 구분\n",
    "gse_counts = df['GSE'].value_counts()\n",
    "gse_index = df.groupby('GSE').cumcount() + 1\n",
    "\n",
    "def make_gse_unique(row):\n",
    "    if gse_counts[row['GSE']] == 1:\n",
    "        return row['GSE']\n",
    "    else:\n",
    "        return f\"{row['GSE']}_{row['gse_index']}\"\n",
    "\n",
    "df['gse_index'] = gse_index\n",
    "df['GSE_unique'] = df.apply(make_gse_unique, axis=1)\n",
    "df = df.drop(columns=['gse_index'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6669556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 20 GSM to SRR                   \n",
      "defaultdict(<class 'list'>, {'GSM3488751': ['SRR8242570', 'SRR8242571'], 'GSM3488752': ['SRR8242572', 'SRR8242573'], 'GSM3488753': ['SRR8242574', 'SRR8242575'], 'GSM3488756': ['SRR8242580', 'SRR8242581'], 'GSM3488757': ['SRR8242582', 'SRR8242583'], 'GSM3488758': ['SRR8242584', 'SRR8242585'], 'GSM4321727': ['SRR11116155'], 'GSM4321728': ['SRR11116156'], 'GSM4321729': ['SRR11116157'], 'GSM4321730': ['SRR11116158'], 'GSM4321723': ['SRR11116151'], 'GSM4321724': ['SRR11116152'], 'GSM4321725': ['SRR11116153'], 'GSM4321726': ['SRR11116154'], 'GSM1836110': ['SRR2569772'], 'GSM1836111': ['SRR2569773'], 'GSM1836112': ['SRR2569774'], 'GSM1836104': ['SRR2569766'], 'GSM1836105': ['SRR2569767'], 'GSM1836106': ['SRR2569768']})\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================#\n",
    "\n",
    "# GSM to SRR 변환\n",
    "gse_gsm_dict = df.groupby('GSE').agg({\n",
    "    'Treat': lambda x: x.iloc[0].split(','),\n",
    "    'Control': lambda x: x.iloc[0].split(',')\n",
    "    \n",
    "}).to_dict(orient='index')\n",
    "\n",
    "gsm_to_srr_i = 0\n",
    "gsm_to_srr_dict = defaultdict(list)\n",
    "for gse, cond_dict in gse_gsm_dict.items():\n",
    "    gsms = cond_dict['Treat'] + cond_dict['Control']\n",
    "    \n",
    "    for gsm in gsms:\n",
    "        gsm_to_srr_i += 1\n",
    "        print(f\"Converting {gsm_to_srr_i} GSM to SRR                   \", end=\"\\r\")\n",
    "        srr = gsm_to_srr(gsm)\n",
    "        if srr:\n",
    "            gsm_to_srr_dict[gsm] += (srr)\n",
    "        else:\n",
    "            log_writer(f\"Failed to convert {gsm} to SRR\", True)\n",
    "\n",
    "print()\n",
    "print(gsm_to_srr_dict)  \n",
    "\n",
    "#=============================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23dc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefetching SRR2569768 for GSM1836106 (GSE71519 3 / 3)                    \r"
     ]
    }
   ],
   "source": [
    "#=============================================================================#\n",
    "\n",
    "def prefetch_srr(srr):\n",
    "    os.system(f\"prefetch {srr} -O ./1_prefetch --max-size u >> log 2>> log\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "def fasterq_dump_srr(srr):\n",
    "    os.system(f\"fasterq-dump ./1_prefetch/{srr} -e 8 -O ./2_fastq >> log 2>> log\")\n",
    "    time.sleep(1)    \n",
    "\n",
    "total_gse_count = len(gse_gsm_dict)\n",
    "gse_i = 0\n",
    "for gse, gsm_dict in gse_gsm_dict.items():\n",
    "    treat_gsm = gsm_dict['Treat']\n",
    "    control_gsm = gsm_dict['Control']\n",
    "    gse_i += 1\n",
    "    \n",
    "    # SRR prefetch\n",
    "    for gsm in treat_gsm + control_gsm:\n",
    "        srr_list = gsm_to_srr_dict[gsm]\n",
    "        for srr in srr_list:\n",
    "            print(f\"Prefetching {srr} for {gsm} ({gse} {gse_i} / {total_gse_count})                  \", end=\"\\r\")\n",
    "            prefetch_srr(srr)\n",
    "    \n",
    "    # 현재 prefetch된 SRA 파일과 fastq 파일 확인\n",
    "    current_prefecthed_arr = glob.glob(f\"./1_prefetch/*/*.sra\")\n",
    "    current_prefecthed_arr = [os.path.basename(path)[:-4] for path in current_prefecthed_arr]\n",
    "    current_fastq_arr = glob.glob(f\"./2_fastq/*.fastq\")\n",
    "    current_fastq_arr = [os.path.basename(path).replace('.', '_').split(\"_\")[0] for path in current_fastq_arr]\n",
    "    \n",
    "    # SRA fasterq-dump\n",
    "    for gsm in treat_gsm + control_gsm:\n",
    "        srr_list = gsm_to_srr_dict[gsm]\n",
    "        for srr in srr_list:\n",
    "            if srr in current_prefecthed_arr:\n",
    "                if not srr in current_fastq_arr:\n",
    "                    print(f\"Fasterq-dump {srr} for {gsm} ({gse} {gse_i} / {total_gse_count})                  \", end=\"\\r\")\n",
    "                    fasterq_dump_srr(srr)\n",
    "                    \n",
    "    # SRR 합치기\n",
    "    current_combined_fastq_arr = glob.glob(f\"./3_fastq_combined/*.fastq\")\n",
    "    current_combined_fastq_arr = [os.path.basename(path).replace('.', '_').split(\"_\")[0] for path in current_combined_fastq_arr]\n",
    "\n",
    "    \n",
    "    for gsm in treat_gsm + control_gsm:\n",
    "        if gsm in current_combined_fastq_arr:\n",
    "            log_writer(f\"{gsm} already combined fastq file exists\", True)\n",
    "            continue\n",
    "        cat_command_1 = \"cat\"\n",
    "        cat_command_2 = \"cat\"\n",
    "        cat_command_single = \"cat\"\n",
    "        srr_list = []\n",
    "        for srrs in gsm_to_srr_dict[gsm]:\n",
    "            \n",
    "            srr_files = sorted(glob.glob(f\"2_fastq/{srrs}*\"))\n",
    "            if len(srr_files) == 2:\n",
    "                is_it_paired = True\n",
    "                cat_command_1 += f\" {srr_files[0]}\"\n",
    "                cat_command_2 += f\" {srr_files[1]}\"\n",
    "                srr_list.append(srr_files[0])\n",
    "                srr_list.append(srr_files[1])\n",
    "            elif len(srr_files) == 1:\n",
    "                is_it_paired = False\n",
    "                cat_command_single += f\" {srr_files[0]}\"\n",
    "                srr_list.append(srr_files[0])\n",
    "            elif len(srr_files) == 3:\n",
    "                is_it_paired = True\n",
    "                cat_command_1 += f\" {srr_files[1]}\"\n",
    "                cat_command_2 += f\" {srr_files[2]}\"\n",
    "                srr_list.append(srr_files[1])\n",
    "                srr_list.append(srr_files[2])\n",
    "                log_writer(f\"{gsm} : {srr} has paired and sigle\" )\n",
    "            else:\n",
    "                log_writer(f\"{gsm} : {srr} not found\" )\n",
    "            #print(cat_command_1, cat_command_2, cat_command_single)\n",
    "            \n",
    "        \n",
    "        if is_it_paired:\n",
    "            cat_command_1 += f\" > ./3_fastq_combined/{gsm}_1.fastq\"\n",
    "            cat_command_2 += f\" > ./3_fastq_combined/{gsm}_2.fastq\"\n",
    "            \n",
    "            try:\n",
    "                print(f\"Combining fastq {gsm} ({gse} {gse_i} / {total_gse_count})                               \", end=\"\\r\")\n",
    "                #os.system(cat_command_1)\n",
    "                #os.system(cat_command_2)\n",
    "                combining_success = True\n",
    "            except:\n",
    "                log_writer(f\"{gsm} fastq combining failed\")\n",
    "\n",
    "        else:\n",
    "            cat_command_single += f\" > ./3_fastq_combined/{gsm}.fastq\"\n",
    "            \n",
    "            try:\n",
    "                print(f\"Combining fastq {gsm} ({gse} {gse_i} / {total_gse_count})                               \", end=\"\\r\")\n",
    "                #os.system(cat_command_single)\n",
    "                log_writer(f\"{gsm} fastq combining end\")\n",
    "                combining_success = True\n",
    "            except:\n",
    "                log_writer(f\"{gsm} fastq combining failed\")\n",
    "                \n",
    "        if combining_success:\n",
    "            for srr in srr_list:\n",
    "                pass\n",
    "                #os.system(f\"rm {srr}\")\n",
    "\n",
    "    # STAR로 align\n",
    "    current_aligned_fastq_arr = glob.glob(f\"./4_aligned/*ReadsPerGene.out.tab\")\n",
    "    current_aligned_fastq_arr = [os.path.basename(path).replace('.', '_').split(\"_\")[0] for path in current_aligned_fastq_arr]\n",
    "    \n",
    "    for gsm in treat_gsm + control_gsm:\n",
    "        if gsm in current_aligned_fastq_arr:\n",
    "            log_writer(f\"{gsm} already aligned\", True)\n",
    "            continue\n",
    "        fastq_files = sorted(glob.glob(f\"3_fastq_combined/{gsm}*\"))\n",
    "        if len(fastq_files) == 2:\n",
    "            read_file_in = f\"{fastq_files[0]} {fastq_files[1]}\"\n",
    "        else:\n",
    "            read_file_in = f\"{fastq_files[0]}\"\n",
    "\n",
    "        STAR_com = f\"STAR --runThreadN {core} --quantMode GeneCounts --outSAMstrandField intronMotif --genomeDir {star_index} --readFilesIn {read_file_in} --outFileNamePrefix ./4_aligned/{gsm}_STAR_\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"STAR aligning {gsm} ({gse} {gse_i} / {total_gse_count})                               \", end=\"\\r\")\n",
    "            os.system(STAR_com)\n",
    "            align_success = True\n",
    "        except:\n",
    "            log_writer(f\"{gsm} aligning failed\")\n",
    "            \n",
    "        if align_success:\n",
    "            for fastq in fastq_files:\n",
    "                pass\n",
    "                #os.system(f\"rm {fastq}\")\n",
    "\n",
    "    # 그룹별로 GSM 분리\n",
    "    if not os.path.isdir(f\"./5_ReadsPerGenes_GSM/{gse}\"):\n",
    "        os.mkdir(f\"./5_ReadsPerGenes_GSM/{gse}\")\n",
    "    if not os.path.isdir(f\"./5_ReadsPerGenes_GSM/{gse}/treat\"):\n",
    "        os.mkdir(f\"./5_ReadsPerGenes_GSM/{gse}/treat\")\n",
    "    if not os.path.isdir(f\"./5_ReadsPerGenes_GSM/{gse}/control\"):\n",
    "        os.mkdir(f\"./5_ReadsPerGenes_GSM/{gse}/control\")\n",
    "        \n",
    "    for gsm in treat_gsm:\n",
    "        current_reads_per_gene = glob.glob(f\"./4_aligned/{gsm}_STAR_ReadsPerGene.out.tab\")\n",
    "        if len(current_reads_per_gene) == 1:\n",
    "            os.system(f\"cp {current_reads_per_gene[0]} ./5_ReadsPerGenes_GSM/{gse}/treat/{gsm}_ReadsPerGene.out.tab\")\n",
    "        else:\n",
    "            log_writer(f\"{gsm} ReadsPerGene file not found\", True)\n",
    "    for gsm in control_gsm:\n",
    "        current_reads_per_gene = glob.glob(f\"./4_aligned/{gsm}_STAR_ReadsPerGene.out.tab\")\n",
    "        if len(current_reads_per_gene) == 1:\n",
    "            os.system(f\"cp {current_reads_per_gene[0]} ./5_ReadsPerGenes_GSM/{gse}/control/{gsm}_ReadsPerGene.out.tab\")\n",
    "        else:\n",
    "            log_writer(f\"{gsm} ReadsPerGene file not found\", True)\n",
    "            \n",
    "    readpergenes_a = sorted(glob.glob(f\"5_ReadsPerGenes_GSM/{gse}/treat/*_ReadsPerGene.out.tab\"))\n",
    "    readpergenes_b = sorted(glob.glob(f\"5_ReadsPerGenes_GSM/{gse}/control/*_ReadsPerGene.out.tab\"))\n",
    "\n",
    "    genes_merged = defaultdict(list)\n",
    "    meta = [[\"id\", \"group\"]]\n",
    "    sample_name = []\n",
    "\n",
    "    for i, reads in enumerate(readpergenes_a):\n",
    "        name = os.path.basename(reads).split(\"_ReadsPerGene\")[0]\n",
    "        sample_name.append(name)\n",
    "        genes_merged[\"id\"].append(f\"A{i+1}\")\n",
    "        meta.append([f\"A{i+1}\",\"A\"])\n",
    "        with open(reads, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines[4:]:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            genes_merged[line[0]].append(line[1])\n",
    "            \n",
    "        print(f\"{i+1} / {len(readpergenes_a)} {gse} treat merged\",end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "    for i, reads in enumerate(readpergenes_b):\n",
    "        name = os.path.basename(reads).split(\"_ReadsPerGene\")[0]\n",
    "        sample_name.append(name)\n",
    "        genes_merged[\"id\"].append(f\"B{i+1}\")\n",
    "        meta.append([f\"B{i+1}\",\"B\"])\n",
    "        with open(reads, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for line in lines[4:]:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            genes_merged[line[0]].append(line[1])\n",
    "            \n",
    "        print(f\"{i+1} / {len(readpergenes_b)} {gse} control merged\",end=\"\\r\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    expression_file_name = f\"6_deseq2_results/merged/{gse}_merged.txt\"\n",
    "    expression_meta_name = f\"6_deseq2_results/merged/{gse}_merged.meta\"\n",
    "\n",
    "    with open(expression_file_name, \"w\") as f:\n",
    "        f.write(\"\\t\".join([\"id\"]+genes_merged[\"id\"])+\"\\n\")\n",
    "        del(genes_merged[\"id\"])\n",
    "        \n",
    "        for gene_name in sorted(genes_merged.keys()):\n",
    "            f.write(\"\\t\".join([gene_name]+genes_merged[gene_name])+\"\\n\")\n",
    "            \n",
    "    with open(expression_meta_name, \"w\") as f:\n",
    "        f.write(\"\\t\".join(meta[0])+\"\\n\")\n",
    "        \n",
    "        for m in meta[1:]:\n",
    "            f.write(\"\\t\".join(m)+\"\\n\")\n",
    "            \n",
    "    with open(\"run_DESeq2.R\", \"w\") as f:\n",
    "        f.write('library(\"DESeq2\")\\n')\n",
    "        f.write(f'x <- read.delim(\"{expression_file_name}\",header=TRUE,row.names=\"id\",sep=\"\\t\")\\n')\n",
    "        f.write('roundx <- round(x)\\n')\n",
    "        f.write(f'coldata <-read.delim(\"{expression_meta_name}\",header=TRUE,row.names=\"id\",sep=\"\\t\")\\n')\n",
    "        f.write('dds <- DESeqDataSetFromMatrix(countData =roundx, colData = coldata, design =~group)\\n')\n",
    "        f.write('dds <- estimateSizeFactors(dds)\\n')\n",
    "        f.write('normalized_counts <- counts(dds, normalized=TRUE)\\n')\n",
    "        f.write(f'write.table(data.frame(\"id\"=rownames(normalized_counts),normalized_counts), file=\"6_deseq2_results/norm/{gse}_expression.deseq2_norm.txt\", sep=\"\\t\", quote=F, col.names=TRUE, row.names=FALSE)\\n')\n",
    "        f.write('des <- DESeq(dds)\\n')\n",
    "        f.write('res <- results(des, contrast=c(\"group\",\"A\",\"B\"))\\n')\n",
    "        f.write(f'write.table(data.frame(\"id\"=rownames(res),res), file=\"6_deseq2_results/deseq2/{gse}_expression.deg.txt\", sep=\"\\t\", quote=F, col.names=TRUE, row.names=FALSE)\\n')\n",
    "        \n",
    "    os.system(f\"Rscript run_DESeq2.R\")\n",
    "    \n",
    "    \n",
    "#=============================================================================#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
